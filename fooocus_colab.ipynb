{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "d1e5f310-834a-4f8a-f35d-ab4cd313aa53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pygit2==1.15.1\n",
            "  Downloading pygit2-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: cffi>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pygit2==1.15.1) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.16.0->pygit2==1.15.1) (2.23)\n",
            "Downloading pygit2-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygit2\n",
            "  Attempting uninstall: pygit2\n",
            "    Found existing installation: pygit2 1.19.0\n",
            "    Uninstalling pygit2-1.19.0:\n",
            "      Successfully uninstalled pygit2-1.19.0\n",
            "Successfully installed pygit2-1.15.1\n",
            "/content\n",
            "Cloning into 'Fooocus'...\n",
            "remote: Enumerating objects: 6730, done.\u001b[K\n",
            "remote: Total 6730 (delta 0), reused 0 (delta 0), pack-reused 6730 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6730/6730), 33.35 MiB | 23.95 MiB/s, done.\n",
            "Resolving deltas: 100% (3848/3848), done.\n",
            "/content/Fooocus\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram']\n",
            "/content/Fooocus/build_launcher.py:9: SyntaxWarning: invalid escape sequence '\\p'\n",
            "  .\\python_embeded\\python.exe -s Fooocus\\entry_with_update.py {cmds} %*\n",
            "Python 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Fooocus version: 2.5.5\n",
            "Error checking version for torchsde: No package metadata was found for torchsde\n",
            "Installing requirements\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/Fooocus/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 11.8MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/Fooocus/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 12.6MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/xl-to-v1_interposer-v4.0.safetensors\" to /content/Fooocus/models/vae_approx/xl-to-v1_interposer-v4.0.safetensors\n",
            "\n",
            "100% 5.40M/5.40M [00:00<00:00, 100MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/Fooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:00<00:00, 415MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_v8Rundiffusion.safetensors\" to /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "\n",
            "100% 6.62G/6.62G [00:47<00:00, 148MB/s] \n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 369MB/s]\n",
            "Total VRAM 15095 MB, total RAM 12976 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "/content/Fooocus/ldm_patched/unipc/uni_pc.py:56: SyntaxWarning: invalid escape sequence '\\h'\n",
            "  The `alphas_cumprod` is the \\hat{alpha_n} arrays in the notations of DDPM. Specifically, DDPMs assume that\n",
            "Refiner unloaded.\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "Running on public URL: https://469fe09d5c175f3158.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.73 seconds\n",
            "2025-11-16 13:44:14.816063: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763300655.054605    1559 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763300655.117837    1559 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763300655.585325    1559 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763300655.585358    1559 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763300655.585362    1559 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763300655.585370    1559 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-16 13:44:15.628792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Started worker with PID 728\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://469fe09d5c175f3158.gradio.live\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8692150831366545834\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] 1girl hot with bikini, intricate, elegant, highly detailed, wonderful quality, exquisite detail, professional, beautiful, cute, best, perfect light, full color, warm colors, romantic, delicate, cool, amazing, pretty, friendly, thought, iconic, fine, dramatic background, illuminated, sharp focus, great composition, cinematic, winning, awesome, creative, artistic\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] 1girl hot with bikini, intricate, elegant, highly detailed, cinematic, light, clear focus, directed, great composition, dynamic, atmosphere, rich detail, creative, beautiful, ambient, fancy, perfect, colorful, epic, smart, fine, best, fair,, chosen, vivid color, illuminated, set, background, contemporary, sharp, designed, professional, grand\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 3.67 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.55 seconds\n",
            "100% 30/30 [00:27<00:00,  1.08it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-11-16/log.html\n",
            "Generating and saving time: 32.52 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.64 seconds\n",
            "100% 30/30 [00:26<00:00,  1.14it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.32 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-11-16/log.html\n",
            "Generating and saving time: 29.83 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 62.35 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 66.06 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.78 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 44362133075271094\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] 1girl hot with bikini and big boobs, big ass, full perfect deep sweet innocent cute pretty exquisite charming, delicate, sublime wonderful elegant detailed supreme quality cinematic composition, magical atmosphere, dynamic dramatic epic beautiful ambient light, sharp focus, great detail, highly intricate, joyful, artistic, fine pure holy, cool attractive, fascinating, marvelous, thought, elite, polished, extremely complex\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] 1girl hot with bikini and big boobs, big ass, full detail, cinematic, dramatic ambient light, sharp focus, intricate, extremely detailed, elegant, innocent, depicted pure aesthetic, fine frank, real sincere, highly coherent, color spread, strong crisp colors, artistic, epic, gorgeous, amazing, great composition, creative, perfect, best, quality, awesome, very\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 2.02 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.21 seconds\n",
            "100% 30/30 [00:28<00:00,  1.04it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-11-16/log.html\n",
            "Generating and saving time: 33.40 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.63 seconds\n",
            "100% 30/30 [00:28<00:00,  1.04it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-11-16/log.html\n",
            "Generating and saving time: 32.35 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 65.75 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 67.83 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.81 seconds\n",
            "Loaded preset: /content/Fooocus/presets/anime.json\n",
            "Downloading: \"https://huggingface.co/mashb1t/fav_models/resolve/main/fav/animaPencilXL_v500.safetensors\" to /content/Fooocus/models/checkpoints/animaPencilXL_v500.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [00:29<00:00, 232MB/s]\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6389488926878567625\n",
            "[Parameters] CFG = 6\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.64 seconds\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/animaPencilXL_v500.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [] for model [/content/Fooocus/models/checkpoints/animaPencilXL_v500.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] 1girl hot with bikini and big boobs, big ass, intricate, elegant, highly detailed, cinematic, light shining, sharp focus, directed, clear, very beautiful, artistic, innocent, inspired, background glowing, attractive, delicate, perfect, emotional, vibrant, cute, confident, passionate, iconic, fine detail, colorful, best, full color, coherent, epic\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] 1girl hot with bikini and big boobs, big ass, full revealing, cozy warm light, cinematic stunning, highly detailed, perfect intricate, beautiful, delicate, sublime, dramatic shining, sharp focus, thought taking, professional spiritual surreal, artistic, inspirational, sacred, shiny, elegant, extremely attractive, majestic, holy, luxury, elite, epic rich, awesome, gorgeous\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 35.53 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.69 seconds\n",
            "100% 30/30 [00:28<00:00,  1.06it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.18 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-11-16/log.html\n",
            "Generating and saving time: 31.73 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "100% 30/30 [00:26<00:00,  1.14it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-11-16/log.html\n",
            "Generating and saving time: 29.11 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 60.84 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.79 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 5795683445831783710\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Downloading control models ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/clip_vision_vit_h.safetensors\" to /content/Fooocus/models/clip_vision/clip_vision_vit_h.safetensors\n",
            "\n",
            "100% 1.84G/1.84G [01:02<00:00, 31.7MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_ip_negative.safetensors\" to /content/Fooocus/models/controlnet/fooocus_ip_negative.safetensors\n",
            "\n",
            "100% 64.1k/64.1k [00:00<00:00, 8.73MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/ip-adapter-plus_sdxl_vit-h.bin\" to /content/Fooocus/models/controlnet/ip-adapter-plus_sdxl_vit-h.bin\n",
            "\n",
            "100% 967M/967M [00:36<00:00, 27.6MB/s]\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.69 seconds\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Create an Ultra-realistic cinematic portrait of the uploaded photo. Copy her face 100%, perfect symmetry, vivid colors, optimistic, detailed, clear, sharp, beautiful, aesthetic, very inspirational, innocent, emotional, futuristic, professional, cheerful, cute, creative, pretty, color, intricate background, inspired, famous, fine, epic, great composition, ambient light, dynamic\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Create an Ultra-realistic cinematic portrait of the uploaded photo. Copy her face 100%, created taking great creative rational artistic expressive intricate, highly detailed, merged aesthetic, wonderful lovely, pure, marvelous, fancy, dramatic background, spectacular atmosphere, thought, perfect, handsome, elegant, magnificent, stunning, epic, futuristic, iconic, fine focus, professional, best, original\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.05 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.40 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 142.07 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.63 seconds\n",
            "100% 30/30 [00:29<00:00,  1.01it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-11-16/log.html\n",
            "Generating and saving time: 33.31 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "100% 30/30 [00:29<00:00,  1.02it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-11-16/log.html\n",
            "Generating and saving time: 32.93 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 66.24 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 208.36 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.78 seconds\n",
            "Loaded preset: /content/Fooocus/presets/realistic.json\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/realisticStockPhoto_v20.safetensors\" to /content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors\n",
            "\n",
            " 42% 2.73G/6.46G [02:16<02:07, 31.3MB/s]Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/model_base_caption_capfilt_large.pth\" to /content/Fooocus/models/clip_vision/model_base_caption_capfilt_large.pth\n",
            "\n",
            "\n",
            "  0% 0.00/855M [00:00<?, ?B/s]\u001b[A\n",
            " 42% 2.74G/6.46G [02:21<06:32, 10.2MB/s]\n",
            "  0% 512k/855M [00:00<07:41, 1.94MB/s]\u001b[A\n",
            "  0% 768k/855M [00:00<07:48, 1.91MB/s]\u001b[A\n",
            "  0% 1.00M/855M [00:00<07:42, 1.93MB/s]\u001b[A\n",
            "  0% 1.25M/855M [00:00<07:54, 1.89MB/s]\u001b[A\n",
            "  0% 1.50M/855M [00:00<07:55, 1.88MB/s]\u001b[A\n",
            "  0% 1.75M/855M [00:00<07:51, 1.90MB/s]\u001b[A\n",
            " 43% 2.75G/6.46G [02:22<06:27, 10.3MB/s]\n",
            " 43% 2.77G/6.46G [02:22<05:02, 13.1MB/s]\n",
            " 43% 2.78G/6.46G [02:22<03:16, 20.1MB/s]\n",
            " 43% 2.80G/6.46G [02:22<02:11, 29.9MB/s]\n",
            "  5% 43.9M/855M [00:01<00:08, 101MB/s] \u001b[A\n",
            " 44% 2.82G/6.46G [02:22<01:44, 37.6MB/s]\n",
            " 44% 2.83G/6.46G [02:27<07:27, 8.71MB/s]\n",
            "  9% 75.9M/855M [00:07<02:09, 6.31MB/s]\u001b[A\n",
            " 44% 2.84G/6.46G [02:28<06:32, 9.90MB/s]\n",
            " 44% 2.85G/6.46G [02:28<05:10, 12.5MB/s]\n",
            " 44% 2.87G/6.46G [02:28<03:33, 18.1MB/s]\n",
            " 45% 2.88G/6.46G [02:28<02:41, 23.9MB/s]\n",
            " 45% 2.89G/6.46G [02:29<03:39, 17.4MB/s]\n",
            " 45% 2.90G/6.46G [02:29<02:46, 22.9MB/s]\n",
            " 45% 2.91G/6.46G [02:29<02:12, 28.7MB/s]\n",
            " 45% 2.92G/6.46G [02:34<07:20, 8.61MB/s]\n",
            " 45% 2.94G/6.46G [02:34<04:45, 13.3MB/s]\n",
            " 21% 183M/855M [00:13<00:54, 12.9MB/s]\u001b[A\n",
            " 46% 2.96G/6.46G [02:34<02:28, 25.4MB/s]\n",
            " 24% 208M/855M [00:13<00:26, 25.5MB/s]\u001b[A\n",
            " 46% 2.97G/6.46G [02:38<07:55, 7.89MB/s]\n",
            " 46% 2.98G/6.46G [02:38<06:25, 9.69MB/s]\n",
            " 46% 3.00G/6.46G [02:44<16:56, 3.66MB/s]\n",
            " 46% 3.00G/6.46G [02:44<13:07, 4.72MB/s]\n",
            " 33% 279M/855M [00:23<01:12, 8.29MB/s]\u001b[A\n",
            " 35% 300M/855M [00:23<00:42, 13.8MB/s]\u001b[A\n",
            " 47% 3.01G/6.46G [02:44<11:24, 5.42MB/s]\n",
            " 47% 3.02G/6.46G [02:50<20:06, 3.06MB/s]\n",
            " 47% 3.03G/6.46G [02:50<11:16, 5.44MB/s]\n",
            " 47% 3.04G/6.46G [02:50<07:08, 8.57MB/s]\n",
            " 47% 3.06G/6.46G [02:50<03:41, 16.5MB/s]\n",
            " 47% 3.07G/6.46G [02:50<02:34, 23.6MB/s]\n",
            " 48% 3.08G/6.46G [02:56<09:40, 6.25MB/s]\n",
            " 48% 3.10G/6.46G [02:56<05:41, 10.6MB/s]\n",
            " 48% 3.12G/6.46G [02:56<03:18, 18.1MB/s]\n",
            " 48% 3.13G/6.46G [02:56<02:19, 25.6MB/s]\n",
            " 49% 3.14G/6.46G [03:00<06:26, 9.22MB/s]\n",
            " 49% 3.15G/6.46G [03:00<05:16, 11.2MB/s]\n",
            " 49% 3.17G/6.46G [03:01<03:36, 16.3MB/s]\n",
            " 49% 3.19G/6.46G [03:01<02:15, 26.0MB/s]\n",
            " 50% 3.20G/6.46G [03:01<01:42, 34.0MB/s]\n",
            " 50% 3.21G/6.46G [03:01<01:23, 41.6MB/s]\n",
            " 50% 3.23G/6.46G [03:06<07:47, 7.44MB/s]\n",
            " 69% 590M/855M [00:46<00:40, 6.81MB/s]\u001b[A\n",
            " 50% 3.25G/6.46G [03:07<04:36, 12.5MB/s]\n",
            " 50% 3.26G/6.46G [03:07<03:27, 16.6MB/s]\n",
            " 51% 3.27G/6.46G [03:13<10:41, 5.35MB/s]\n",
            " 51% 3.27G/6.46G [03:13<08:42, 6.56MB/s]\n",
            " 51% 3.29G/6.46G [03:13<05:39, 10.0MB/s]\n",
            " 51% 3.30G/6.46G [03:13<04:05, 13.8MB/s]\n",
            " 51% 3.31G/6.46G [03:13<02:49, 19.9MB/s]\n",
            " 51% 3.32G/6.46G [03:13<02:09, 26.1MB/s]\n",
            " 52% 3.33G/6.46G [03:19<09:42, 5.77MB/s]\n",
            " 52% 3.34G/6.46G [03:19<07:49, 7.15MB/s]\n",
            " 52% 3.35G/6.46G [03:19<05:16, 10.6MB/s]\n",
            " 52% 3.37G/6.46G [03:19<03:07, 17.8MB/s]\n",
            " 52% 3.38G/6.46G [03:19<02:01, 27.1MB/s]\n",
            " 88% 748M/855M [00:58<00:05, 20.5MB/s]\u001b[A\n",
            " 53% 3.40G/6.46G [03:23<05:30, 9.96MB/s]\n",
            " 53% 3.41G/6.46G [03:23<04:25, 12.3MB/s]\n",
            " 53% 3.43G/6.46G [03:23<02:43, 19.9MB/s]\n",
            " 53% 3.44G/6.46G [03:23<02:10, 24.8MB/s]\n",
            " 53% 3.45G/6.46G [03:23<01:34, 34.1MB/s]\n",
            " 54% 3.47G/6.46G [03:29<07:23, 7.25MB/s]\n",
            " 54% 3.52G/6.46G [03:29<02:07, 24.9MB/s]\n",
            " 55% 3.55G/6.46G [03:29<01:19, 39.3MB/s]\n",
            "100% 855M/855M [01:09<00:00, 12.9MB/s]\n",
            " 62% 3.99G/6.46G [03:58<01:08, 38.5MB/s]load checkpoint from /content/Fooocus/models/clip_vision/model_base_caption_capfilt_large.pth\n",
            "Requested to load BLIP_Decoder\n",
            "Loading 1 new model\n",
            " 64% 4.11G/6.46G [04:05<00:29, 84.4MB/s][Fooocus Model Management] Moving model(s) has taken 6.32 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 488, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1431, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1103, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 976, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/webui.py\", line 1070, in trigger_describe\n",
            "    describe_prompts.append(default_interrogator_photo(img))\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/extras/interrogate.py\", line 52, in interrogate\n",
            "    gpu_image = transforms.Compose([\n",
            "                ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n",
            "    img = t(img)\n",
            "          ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py\", line 137, in __call__\n",
            "    return F.to_tensor(pic)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/transforms/functional.py\", line 142, in to_tensor\n",
            "    raise TypeError(f\"pic should be PIL Image or ndarray. Got {type(pic)}\")\n",
            "TypeError: pic should be PIL Image or ndarray. Got <class 'NoneType'>\n",
            "100% 6.46G/6.46G [07:47<00:00, 14.8MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/fav_models/resolve/main/fav/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors\" to /content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors\n",
            "\n",
            "100% 870M/870M [01:19<00:00, 11.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install pygit2==1.15.1\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus\n",
        "!python entry_with_update.py --share --always-high-vram\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}